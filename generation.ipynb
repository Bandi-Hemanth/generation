{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ7zf2eNr1WA",
        "outputId": "2d2c754f-6462-41ff-80d5-cf4aca979ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhTW6l7D7lnI",
        "outputId": "86fabb58-c355-43bc-d489-b5606405dd8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.23.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.62.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.models"
      ],
      "metadata": {
        "id": "Txe8HTvUuiNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGhbGlsoFywU"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, TFBertModel, GPT2Tokenizer, TFGPT2Model\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow_datasets import load\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate, LSTM, Embedding, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder, LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_img_train = (\"https://www.pexels.com/photo/elephants-on-brown-mountain-631317/\", \"https://www.google.com/imgres?imgurl=https%3A%2F%2Fwallpapers.com%2Fimages%2Fhd%2Fnational-geographic-predator-silhouette-4z13g83xxc7xn5x3.jpg&tbnid=VzNU4MX1n3FYVM&vet=12ahUKEwjM79v-zvuDAxXAcGwGHSLZCjYQMygNegQIARBv..i&imgrefurl=https%3A%2F%2Fwallpapers.com%2Fnational-geographic&docid=7ky-x1XgTMZIrM&w=1920&h=1270&q=geographic%20hd%20pics&ved=2ahUKEwjM79v-zvuDAxXAcGwGHSLZCjYQMygNegQIARBv\")\n",
        "image_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2)"
      ],
      "metadata": {
        "id": "yxDEYBCiG3Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "max_len=30\n",
        "X_bert_train=[]\n",
        "for input in text_sequences:\n",
        "    tokens = bert_tokenizer(input, padding='max_length', truncation=True, max_length=max_len, return_tensors='np')\n",
        "    X_bert_train.append(tokens['input_ids'])\n",
        "\n",
        "X_bert_train = np.array(X_bert_train)\n",
        "\n",
        "bert_model = TFBertModel.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "max_len_gpt2=30\n",
        "X_gpt2_train=[]\n",
        "gpt2_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "for input in text_sequences:\n",
        "    tokens = gpt2_tokenizer(input, padding='max_length', truncation=True, max_length=max_len_gpt2, return_tensors='np')\n",
        "    X_gpt2_train.append(tokens['input_ids'])\n",
        "X_gpt2_train = np.array(X_gpt2_train)\n",
        "\n",
        "gpt2_model = TFGPT2Model.from_pretrained('gpt2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wyCcRCzG_wy",
        "outputId": "de17da56-0c13-4c6f-f6f7-0dc29725a284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "All PyTorch model weights were used when initializing TFGPT2Model.\n",
            "\n",
            "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "kgZt42buui7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = Input(shape=(299, 299, 3))\n",
        "image_features = Conv2D(64, (3, 3), activation='relu')(image_input)\n",
        "image_features = MaxPooling2D(pool_size=(2, 2))(image_features)\n",
        "image_features = Flatten()(image_features)\n",
        "image_features = Dense(256, activation='relu')(image_features)\n",
        "vocab_size=10000\n",
        "X_seq_train= [\"how many elephants\", \"color of elephants\"]\n",
        "text_input = Input(shape=(max_len,))\n",
        "text_features = Embedding(input_dim=vocab_size, output_dim=256, input_length=max_len)(text_input)\n",
        "text_features = LSTM(256, return_sequences=False)(text_features)\n",
        "bert_input = Input(shape=(max_len,), dtype='int32')\n",
        "bert_output= bert_model(bert_input)['pooler_output']\n",
        "bert_features =Dense(256, activation='relu')(bert_output) # [1] returns the pooled output\n",
        "gpt2_input = Input(shape=(max_len,))\n",
        "gpt2_features = gpt2_model(gpt2_input)[0][:, 0, :]  # Using the CLS token representation\n",
        "\n",
        "concatenated_features = Concatenate()([image_features, text_features, bert_features, gpt2_features])\n",
        "\n",
        "output = Dense(vocab_size, activation='softmax')(concatenated_features)\n",
        "\n",
        "model = Model(inputs=[image_input, text_input, bert_input, gpt2_input], outputs=output)\n"
      ],
      "metadata": {
        "id": "dJjpI0MgHG8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = Adam(learning_rate=0.001)  # Adjust learning rate based on experimentation\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "waVe0-WxKqBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder= LabelEncoder()\n",
        "labels=[\"12\", \"black\"]\n",
        "y_train = label_encoder.fit_transform(labels)\n",
        "y_train_one_hot= to_categorical(y_train)"
      ],
      "metadata": {
        "id": "-4IuDs8Tv6ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "batch_size=32"
      ],
      "metadata": {
        "id": "yMFl3s-Wz463"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your augmented image and question data ready in X_img_train, X_seq_train, and y_train\n",
        "model.fit([X_img_train, X_seq_train, X_bert_train, X_gpt2_train], y_train, epochs = epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "_3b-QzBaK65Z",
        "outputId": "44bb4e2d-bccf-451a-e1bc-5e8da69180a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'tuple\\'> containing values of types {\"<class \\'str\\'>\"})', '(<class \\'list\\'> containing values of types {\"<class \\'str\\'>\"})', \"<class 'numpy.ndarray'>\"}), <class 'numpy.ndarray'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-cc6bf7f9b235>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming you have your augmented image and question data ready in X_img_train, X_seq_train, and y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_img_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_seq_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_bert_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_gpt2_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1106\u001b[0m             \"Failed to find data adapter that can handle input: {}, {}\".format(\n\u001b[1;32m   1107\u001b[0m                 \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \\'tuple\\'> containing values of types {\"<class \\'str\\'>\"})', '(<class \\'list\\'> containing values of types {\"<class \\'str\\'>\"})', \"<class 'numpy.ndarray'>\"}), <class 'numpy.ndarray'>"
          ]
        }
      ]
    },
    {
      "source": [
        "print(type(X_img_train))\n",
        "print(type(X_seq_train))\n",
        "print(type(X_bert_train))\n",
        "print(type(X_gpt2_train))\n",
        "print(type(y_train))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UWykicH4ty6",
        "outputId": "c605c0bd-5a70-4258-9128-5d772ec68d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "source": [
        "print(X_img_train.shape)\n",
        "print(X_seq_train.shape)\n",
        "print(X_bert_train.shape)\n",
        "print(X_gpt2_train.shape)\n",
        "print(y_train.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "uea_F9AL4zIB",
        "outputId": "6dabb1e8-9f02-4bc4-9444-2ac5304abcfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-fa2e139a7571>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_img_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_seq_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_bert_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gpt2_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "source": [
        "model.summary()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4Fq8anmup74",
        "outputId": "63629875-e6ed-4954-a306-83962b4abb62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 299, 299, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 297, 297, 64)         1792      ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 148, 148, 64)         0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)        [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 30)]                 0         []                            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 1401856)              0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 30, 256)              2560000   ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertMod  TFBaseModelOutputWithPooli   3351418   ['input_7[0][0]']             \n",
            " el)                         ngAndCrossAttentions(last_   88                                      \n",
            "                             hidden_state=(None, 30, 10                                           \n",
            "                             24),                                                                 \n",
            "                              pooler_output=(None, 1024                                           \n",
            "                             ),                                                                   \n",
            "                              past_key_values=None, hid                                           \n",
            "                             den_states=None, attention                                           \n",
            "                             s=None, cross_attentions=N                                           \n",
            "                             one)                                                                 \n",
            "                                                                                                  \n",
            " tfgpt2_model_1 (TFGPT2Mode  TFBaseModelOutputWithPastA   1244398   ['input_8[0][0]']             \n",
            " l)                          ndCrossAttentions(last_hid   08                                      \n",
            "                             den_state=(None, 30, 768),                                           \n",
            "                              past_key_values=((2, None                                           \n",
            "                             , 12, 30, 64),                                                       \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64),                                              \n",
            "                              (2, None, 12, 30, 64)),                                             \n",
            "                              hidden_states=None, atten                                           \n",
            "                             tions=None, cross_attentio                                           \n",
            "                             ns=None)                                                             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 256)                  3588753   ['flatten_1[0][0]']           \n",
            "                                                          92                                      \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 256)                  525312    ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 256)                  262400    ['tf_bert_model_1[0][1]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  (None, 768)                  0         ['tfgpt2_model_1[0][0]']      \n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 1536)                 0         ['dense_3[0][0]',             \n",
            " )                                                                   'lstm_1[0][0]',              \n",
            "                                                                     'dense_4[0][0]',             \n",
            "                                                                     'tf.__operators__.getitem_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 10000)                1537000   ['concatenate_1[0][0]']       \n",
            "                                                          0                                       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 837176592 (3.12 GB)\n",
            "Trainable params: 837176592 (3.12 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}